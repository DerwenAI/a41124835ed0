{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 09: Word2Vect example\n",
    "\n",
    "The data file `terms.tsv` has 10K elements, which is a subset from a **much** larger file.\n",
    "This represents the keyphrases from 843 unique documents.\n",
    "Realistically, you want many more documents in a *Word2Vec* model before the results begin to make a lot of sense.\n",
    "\n",
    "Even so, this is enough to show how to call the functions from [gensim](https://radimrehurek.com/gensim/models/word2vec.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gensim\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "model_file = \"model.dat\"\n",
    "term_path = \"terms.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the parsed keyphrases into a list called `sentences`, where each \"sentence\" is the list of keyphrases from one document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sent = []\n",
    "last_doc = None\n",
    "\n",
    "with open(term_path) as f:\n",
    "    for term, doc, rank in csv.reader(f, delimiter=\"\\t\"):\n",
    "        rank = float(rank)\n",
    "\n",
    "        if doc != last_doc:\n",
    "            if last_doc:\n",
    "                sentences.append(sent)\n",
    "                sent = []\n",
    "\n",
    "            last_doc = doc\n",
    "\n",
    "        sent.append(term)\n",
    "\n",
    "    # handle the dangling last element\n",
    "    sentences.append(sent)\n",
    "\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging (which is required by `gensim`) then train `word2vec` on each \"sentence\". Then save the model to the `model.dat` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMAT = \"%(asctime)s : %(levelname)s : %(message)\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.ERROR)\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to load a trained model, use:\n",
    "`model = gensim.models.Word2Vec.load(model_file)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sx ls -lth model.dat terms.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a helper method, which queries the resulting model for \"neighbor\" keyphrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synset (model, query, topn=10):\n",
    "    try:\n",
    "        return sorted(model.wv.most_similar(positive=[query], topn=topn), key=lambda x: x[1], reverse=True)\n",
    "    except KeyError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query the model interactively through a mini REPL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RESULTS = 10\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        query = input(\"\\nquery? \")\n",
    "        synset = get_synset(model, query, topn=NUM_RESULTS)\n",
    "        print(\"most similar to\", query, \":\", synset)\n",
    "    except KeyError:\n",
    "        print(\"not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
